{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GITHUB https://github.com/Kel-340/InteligenciaArtificial\n",
        "DATASET https://www.kaggle.com/datasets/colewelkins/cardiovascular-disease"
      ],
      "metadata": {
        "id": "HfpN5ttxMEGk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9yYHj2Na5Wx",
        "outputId": "120cac70-59d0-4b50-e8ed-d595ee2a33f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utilizado para la manipulación de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Cálculo científico y vectorial para python\n",
        "import numpy as np\n",
        "\n",
        "# Libreria para graficos\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Modulo de optimizacion en scipy\n",
        "from scipy import optimize\n",
        "\n",
        "# modulo para cargar archivos en formato MATLAB\n",
        "# from scipy.io import loadmat\n",
        "\n",
        "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ybb0vSaqcIX8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 4 etiquetas, de 0 a 3 (normal = 0, hypertension1 = 1, hypertension2 = 2, Elevated: 3)\n",
        "num_labels = 4\n",
        "\n",
        "# Cargar los datos usando Pandas\n",
        "df = pd.read_csv('/content/sample_data/cardio_data_processed.csv')\n",
        "\n",
        "# Omitir la columna 0(no tiene relevancia pq es la numeración de las filas) en X y la columna 17(es una columna repetida de Y)\n",
        "X_test = df.iloc[0:54500, 1:15].values\n",
        "y_test = df.iloc[0:54500:, 16].values\n",
        "\n",
        "X_train = df.iloc[54500:, 1:15].values\n",
        "y_train = df.iloc[54500:, 16].values\n",
        "\n",
        "\n",
        "X=X_test\n",
        "y=y_test\n",
        "\n",
        "#X=X_train\n",
        "#y=y_train\n",
        "\n",
        "# Mapear los valores de la columna 16 según la lógica (normal = 0, hypertension1 = 1, hypertension2 = 2, Elevated: 3)\n",
        "mapping = {\n",
        "    'Hypertension Stage 1': 1,\n",
        "    'Hypertension Stage 2': 2,\n",
        "    'Normal': 0,\n",
        "    'Elevated': 3\n",
        "}\n",
        "\n",
        "# Reemplazar los valores en la columna de etiquetas según el diccionario de mapeo\n",
        "y_mapped = np.array([mapping[val] for val in y])\n",
        "y=y_mapped\n",
        "y[y == 4] = 0\n",
        "\n",
        "\n",
        "\n",
        "print(X)\n",
        "\n",
        "m = y.size"
      ],
      "metadata": {
        "id": "uMek8P0MdI41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf36624-81c1-491e-b816-61573517a402"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.02280000e+04 1.00000000e+00 1.56000000e+02 ... 1.00000000e+00\n",
            "  5.50000000e+01 3.49276792e+01]\n",
            " [1.88570000e+04 1.00000000e+00 1.65000000e+02 ... 1.00000000e+00\n",
            "  5.10000000e+01 2.35078053e+01]\n",
            " [1.76230000e+04 2.00000000e+00 1.69000000e+02 ... 1.00000000e+00\n",
            "  4.80000000e+01 2.87104793e+01]\n",
            " ...\n",
            " [1.89110000e+04 1.00000000e+00 1.53000000e+02 ... 1.00000000e+00\n",
            "  5.10000000e+01 3.11845871e+01]\n",
            " [2.05350000e+04 1.00000000e+00 1.65000000e+02 ... 0.00000000e+00\n",
            "  5.60000000e+01 2.75482094e+01]\n",
            " [2.28220000e+04 1.00000000e+00 1.51000000e+02 ... 1.00000000e+00\n",
            "  6.20000000e+01 4.07876848e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBfI2myzLuWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9C5ubig5nne",
        "outputId": "4a09a246-df9b-4e35-c596-6e51372c7021"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.02280000e+04 1.00000000e+00 1.56000000e+02 ... 1.00000000e+00\n",
            "  5.50000000e+01 3.49276792e+01]\n",
            " [1.88570000e+04 1.00000000e+00 1.65000000e+02 ... 1.00000000e+00\n",
            "  5.10000000e+01 2.35078053e+01]\n",
            " [1.76230000e+04 2.00000000e+00 1.69000000e+02 ... 1.00000000e+00\n",
            "  4.80000000e+01 2.87104793e+01]\n",
            " ...\n",
            " [1.89110000e+04 1.00000000e+00 1.53000000e+02 ... 1.00000000e+00\n",
            "  5.10000000e+01 3.11845871e+01]\n",
            " [2.05350000e+04 1.00000000e+00 1.65000000e+02 ... 0.00000000e+00\n",
            "  5.60000000e+01 2.75482094e+01]\n",
            " [2.28220000e+04 1.00000000e+00 1.51000000e+02 ... 1.00000000e+00\n",
            "  6.20000000e+01 4.07876848e+01]]\n",
            "[2 1 2 ... 1 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normaliza y estandariza los datos de X\n",
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "\n",
        "    return X_norm, mu, sigma"
      ],
      "metadata": {
        "id": "HfcYHkxM21PV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X)"
      ],
      "metadata": {
        "id": "kyWBo8Uf23cr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n",
        "m, n = X.shape\n",
        "# Agraga el termino de intercepción a A\n",
        "# X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
        "X = X_norm\n",
        "# X = np.concatenate([np.ones((m, 1)), X], axis=1)"
      ],
      "metadata": {
        "id": "yTKzYjJt3RJu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecciona aleatoriamente 100 puntos de datos para mostrar\n",
        "rand_indices = np.random.choice(m, 100, replace=False)\n",
        "sel = X[rand_indices, :]\n",
        "\n",
        "# displayData(sel)"
      ],
      "metadata": {
        "id": "ddOFdKkI3kJk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Calcula la sigmoide de z.\n",
        "    \"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-z))"
      ],
      "metadata": {
        "id": "Pe8jfElW3nsz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lrCostFunction(theta, X, y, lambda_):\n",
        "    \"\"\"\n",
        "    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y\n",
        "    el gradiente del costo w.r.t. a los parámetros.\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    theta : array_like\n",
        "        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas\n",
        "        incluida la intercepcion\n",
        "\n",
        "    X : array_like\n",
        "        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de\n",
        "        caracteristicas (incluida la intercepcion).\n",
        "\n",
        "    y : array_like\n",
        "        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n",
        "\n",
        "    lambda_ : float\n",
        "        Parametro de regularización.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    J : float\n",
        "        El valor calculado para la funcion de costo regularizada.\n",
        "\n",
        "    grad : array_like\n",
        "        Un vector de la forma (shape) (n, ) que es el gradiente de la\n",
        "        función de costo con respecto a theta, en los valores actuales de theta..\n",
        "    \"\"\"\n",
        "#     alpha = 0.003\n",
        "#     theta = theta.copy()\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y.size\n",
        "\n",
        "    # convierte las etiquetas a valores enteros si son boleanos\n",
        "    if y.dtype == bool:\n",
        "        y = y.astype(int)\n",
        "\n",
        "    J = 0\n",
        "    grad = np.zeros(theta.shape)\n",
        "\n",
        "    h = sigmoid(X.dot(theta.T))\n",
        "\n",
        "    temp = theta\n",
        "    temp[0] = 0\n",
        "\n",
        "#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
        "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
        "\n",
        "    grad = (1 / m) * (h - y).dot(X)\n",
        "#     theta = theta - (alpha / m) * (h - y).dot(X)\n",
        "    grad = grad + (lambda_ / m) * temp\n",
        "\n",
        "    return J, grad\n",
        "#    return J, theta"
      ],
      "metadata": {
        "id": "8ksMN2mZ3qi1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def oneVsAll(X, y, num_labels, lambda_):\n",
        "    \"\"\"\n",
        "    Trains num_labels logistic regression classifiers and returns\n",
        "    each of these classifiers in a matrix all_theta, where the i-th\n",
        "    row of all_theta corresponds to the classifier for label i.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array_like\n",
        "        The input dataset of shape (m x n). m is the number of\n",
        "        data points, and n is the number of features. Note that we\n",
        "        do not assume that the intercept term (or bias) is in X, however\n",
        "        we provide the code below to add the bias term to X.\n",
        "\n",
        "    y : array_like\n",
        "        The data labels. A vector of shape (m, ).\n",
        "\n",
        "    num_labels : int\n",
        "        Number of possible labels.\n",
        "\n",
        "    lambda_ : float\n",
        "        The logistic regularization parameter.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        (ie. `numlabels`) and n is number of features without the bias.\n",
        "    \"\"\"\n",
        "    # algunas variables utiles\n",
        "    m, n = X.shape\n",
        "\n",
        "    all_theta = np.zeros((num_labels, n + 1))\n",
        "\n",
        "    # Agrega unos a la matriz X\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "    # realiza la clasificación multiclase utilizando regresión logística regularizada\n",
        "    for c in np.arange(num_labels):\n",
        "        initial_theta = np.zeros(n + 1)\n",
        "        options = {'maxiter': 50}\n",
        "        res = optimize.minimize(lrCostFunction,\n",
        "                                initial_theta,\n",
        "                                (X, (y == c), lambda_),\n",
        "                                jac=True,\n",
        "                                method='CG',\n",
        "                                options=options)\n",
        "\n",
        "        all_theta[c] = res.x\n",
        "\n",
        "    return all_theta\n"
      ],
      "metadata": {
        "id": "oH9b1UIA3vOa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#llama a la función oneVsAll para entrenar un clasificador de regresión\n",
        "#logística multiclase utilizando el enfoque de \"Uno contra Todos\" (One-vs-All) y\n",
        "#luego imprimiendo la forma de la matriz all_theta resultante\n",
        "lambda_ = 0.1\n",
        "all_theta = oneVsAll(X, y, num_labels, lambda_)\n",
        "print(all_theta.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfY4dttf3xwr",
        "outputId": "d7cd63c3-56dc-4ecc-b6b0-6d9bed88eaae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjD3hFbw6ucE",
        "outputId": "609053fa-2bf5-465c-88eb-c5851e13e662"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.25909938e+01 -3.58416196e-02 -9.92990756e-02 -9.36157886e-02\n",
            "   3.82789556e-02 -8.36841500e+00 -4.68817073e+00  1.15904126e-01\n",
            "  -4.69229516e-02 -1.40639179e-02  7.49753067e-03 -8.19444803e-03\n",
            "  -3.61306925e-02 -7.99450426e-02 -3.64524876e-02]\n",
            " [ 3.45158442e-01  1.40552527e-01  1.89124714e-02  1.86374535e-01\n",
            "  -7.79419397e-02 -6.97373558e-01  4.04145322e-01 -5.46657281e-02\n",
            "   2.54979479e-02 -2.13604461e-02 -2.62431800e-02 -2.07203025e-02\n",
            "  -1.00037637e-01  4.44688266e-02  1.15775837e-01]\n",
            " [-3.20530438e+00 -2.12636428e-02 -5.30675752e-04  5.23088730e-02\n",
            "  -1.20489079e-01  1.80243443e+00  2.93435118e+00 -4.63720204e-02\n",
            "   2.49472454e-02 -2.98132486e-02  3.75322664e-04 -9.17773993e-03\n",
            "   5.86547181e-02 -1.53851381e-02  3.86309214e-02]\n",
            " [-4.20969657e+00  2.88984526e-02  7.11599192e-02  1.91178301e-01\n",
            "  -1.44221126e-01  1.00283830e+00 -2.17417854e+00 -1.76219485e-01\n",
            "   3.90697396e-02 -3.77918406e-02  3.43822541e-02 -3.44170441e-02\n",
            "  -2.39020365e-01  5.27671120e-02  1.08938843e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictOneVsAll(all_theta, X):\n",
        "    \"\"\"\n",
        "    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n",
        "    Tenga en cuenta que X contiene los ejemplos en filas.\n",
        "    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase.\n",
        "    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1]\n",
        "    predice clases 0, 2, 0, 1 para 4 ejemplos).\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        and n is number of features without the bias.\n",
        "\n",
        "    X : array_like\n",
        "        Data points to predict their labels. This is a matrix of shape\n",
        "        (m x n) where m is number of data points to predict, and n is number\n",
        "        of features without the bias term. Note we add the bias term for X in\n",
        "        this function.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    p : array_like\n",
        "        The predictions for each data point in X. This is a vector of shape (m, ).\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[0];\n",
        "    num_labels = all_theta.shape[0]\n",
        "\n",
        "    p = np.zeros(m)\n",
        "\n",
        "    # Add ones to the X data matrix\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
        "\n",
        "    return p"
      ],
      "metadata": {
        "id": "_FkdVCil6xLC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "pred = predictOneVsAll(all_theta, X)\n",
        "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
        "XPrueba = X[1:140, :].copy()\n",
        "print(XPrueba.shape)\n",
        "#print(np.ones((1)))\n",
        "#print(XPrueba)\n",
        "#p = np.zeros(1)\n",
        "XPrueba = np.concatenate([np.ones((139, 1)), XPrueba], axis=1)\n",
        "print(XPrueba.shape)\n",
        "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n",
        "print(p)\n",
        "\n",
        "# displayData(X[1002:1003, :])\n",
        "print(y[1:140])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx1_PzDb60Sz",
        "outputId": "bd2a4917-16b0-44ef-bf0b-7f506a118a04"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54500, 14)\n",
            "Precision del conjuto de entrenamiento: 89.86%\n",
            "(139, 14)\n",
            "(139, 15)\n",
            "[1 2 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 2 0 2 2 1 1 1 1 1 2 0 1 2 1 1 1 1\n",
            " 2 0 1 2 0 2 2 2 1 1 1 0 2 2 2 1 1 0 1 2 2 0 2 1 1 1 1 1 2 2 0 1 2 0 2 2 1\n",
            " 1 2 2 1 1 1 1 2 1 0 2 2 1 1 2 2 2 2 1 0 0 2 1 1 0 0 1 1 2 1 0 1 0 1 1 0 1\n",
            " 1 2 1 1 0 0 1 1 2 0 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1]\n",
            "[1 2 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 3 1 1 1 0 2 1 1 1 1 1 1 2 0 1 2 1 1 1 1\n",
            " 2 0 1 2 3 1 2 2 1 1 3 0 2 2 1 1 2 0 1 2 2 0 2 1 1 1 1 1 2 2 0 1 2 0 2 2 1\n",
            " 1 2 2 1 3 3 1 2 1 0 2 2 1 1 2 2 2 2 1 0 0 2 1 1 0 0 1 1 2 1 0 1 0 1 1 0 3\n",
            " 1 2 1 1 0 0 1 1 2 0 2 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#usamos x_train para comprobar que el aprendizaje predice los valores de y_train\n",
        "pred = predictOneVsAll(all_theta, X)\n",
        "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
        "XPrueba = X_train[1:140, :].copy()\n",
        "print(XPrueba.shape)\n",
        "#print(np.ones((1)))\n",
        "#print(XPrueba)\n",
        "#p = np.zeros(1)\n",
        "# Normalizar XPrueba utilizando las medias y desviaciones estándar de X_train\n",
        "XPrueba_norm = (XPrueba - mu) / sigma\n",
        "\n",
        "# Agregar la columna de unos\n",
        "XPrueba_norm_con_intercepto = np.concatenate([np.ones((XPrueba_norm.shape[0], 1)), XPrueba_norm], axis=1)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba normalizado\n",
        "p = np.argmax(sigmoid(XPrueba_norm_con_intercepto.dot(all_theta.T)), axis=1)\n",
        "print(p)\n",
        "\n",
        "# displayData(X[1002:1003, :])\n",
        "print(y_train[1:140])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z6EqZvvKgss",
        "outputId": "b293d4ee-853c-4e6d-d15d-3d94c1aa30d4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision del conjuto de entrenamiento: 89.86%\n",
            "(139, 14)\n",
            "[2 1 1 0 1 2 1 1 1 2 0 2 2 1 2 1 1 1 2 1 1 1 1 1 1 0 2 1 1 1 2 1 1 2 1 1 1\n",
            " 1 1 1 0 2 2 1 2 0 1 0 1 1 1 1 2 2 1 1 1 1 1 1 2 0 1 2 0 0 2 1 2 1 1 1 0 1\n",
            " 1 0 1 2 2 1 0 2 1 1 1 1 2 3 0 1 1 2 2 1 1 1 2 1 2 2 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 0 0 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 0 1 1 1 1 1 1]\n",
            "['Hypertension Stage 2' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Normal' 'Hypertension Stage 1' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 2' 'Normal' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 2' 'Hypertension Stage 1' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Elevated'\n",
            " 'Hypertension Stage 2' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Normal' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 2' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 2' 'Elevated' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 2' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Normal' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 2' 'Hypertension Stage 1' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Elevated' 'Normal' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 2' 'Hypertension Stage 2' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 2'\n",
            " 'Normal' 'Hypertension Stage 1' 'Hypertension Stage 1' 'Normal' 'Normal'\n",
            " 'Hypertension Stage 2' 'Hypertension Stage 1' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Normal' 'Hypertension Stage 1' 'Hypertension Stage 1' 'Normal'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 2' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Normal' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 2' 'Hypertension Stage 2'\n",
            " 'Normal' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 2' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Elevated' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 2' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Elevated' 'Hypertension Stage 1' 'Elevated'\n",
            " 'Hypertension Stage 1' 'Normal' 'Normal' 'Normal' 'Normal' 'Normal'\n",
            " 'Elevated' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 2' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 2'\n",
            " 'Hypertension Stage 2' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1' 'Hypertension Stage 1'\n",
            " 'Hypertension Stage 1' 'Hypertension Stage 1']\n"
          ]
        }
      ]
    }
  ]
}